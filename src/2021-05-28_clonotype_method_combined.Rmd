---
title: "Using the new clonotype method in all samples"
author: "Rodrigo Arcoverde"
date: '`r format(Sys.Date(), "%Y-%m-%d")`'
output: html_document
abstract: Test the improved version of clonotype/clonoquery method.
knit: (function(inputFile, encoding) {
          rmarkdown::render(inputFile,
                            encoding = encoding, 
                            output_file = paste0(
                              xfun::sans_ext(inputFile), '_', Sys.Date(), '.html'),
                                output_dir = "../results/lab_book/")})
---

```{r setup, include=FALSE}
knitr::opts_knit$set(echo = TRUE,
                     root.dir = getwd(),
                     fig.width = 6, fig.height = 5,
                     warning = FALSE, 
                     message = FALSE)

result.dir <- paste0("results/",Sys.Date(),"/")

## creates result.dir with date in if not existent
ifelse(isFALSE(dir.exists(paste0("../",result.dir))), dir.create(paste0("../",result.dir),recursive = TRUE),"Result directory for today exists already!")
options(stringsAsFactors = FALSE) 
```

## Background
Previously, according to Ganesh et al. (2020), the workflow for IgDiscover clonotype is the following:
  * Run clonotype module on antigen-specific single-cells
  * Use the output of clonotype to run igdiscover again to generate filtered tabs
  * Use the filtered tabs for query the large dataset
However, this takes only one representive of a single clone to search on the repertoire sequencing dataset, thus it could potentially decrease the size of clones due to not being similar to the reference sequence used but still being part of the clone compared to other sequence. 
For this reason, we previously tested different ways to overcome this, see another Rmarkdown with the comparison of the methods. The approach used here was the best solution for us that was able to increase the clonotype detection besides avoiding extensive post-processing in R. This approach consists in combining all the datasets, adding a new name to identify the timepoint and subject ID on the sequence name, and with this combined dataset, just run `igdiscover clonotypes` as we normally would.
This Rmarkdown file was created for generating the post-processing following the clonotype run with the combined dataset, create intermediate files for following analysis, and calculate diversity indexes.


## Needed libraries
```{r libraries, message=FALSE}
library(data.table)
library(dplyr)
library(vegan)
library(ggplot2)
```

## Load data
```{r message=FALSE, warning=FALSE}
#clonotypes file processed after igdiscover gene assignment, combining outputs from all samples, and running clonotype module with traditional clonotype definition (aka same HV and HJ, same HCDR3 length, 80% aa similarities, and at least junction nucleotide the same)

clonotype_full <- fread("../data/processed_data/filtered_tsv/nestor-rm/clonotypes_full.txt.gz", sep = "\t", quote = FALSE, header = TRUE, verbose = TRUE, nThread = 8, fill = TRUE)



## specificity for all antigen-specific single-cells from FACS-sorting
query_ref <- read.csv("../data/specificity/fsc_combined_processed_specificity.csv") %>% 
  na.omit() %>%
  dplyr::rename(name = file_ID,
                specificity_full = specificity) %>%
  mutate(specificity = gsub("\\d+", "",specificity_full))

```

## Processing data

```{r data_wrangling}

#create clonotype groups for all the sequences based on the IgDiscover clonotype module output
#creating a grp variable based on the empty rows, which are the separation between different clones from the igdiscover output
clonotype_full_fixed <- clonotype_full %>%
  mutate(grp = cumsum(is.na(CDR3_length)),
         name = gsub(".filtered.tsv.gz|sc_cirelli.tsv.gz_|cirelli_filtered.tsv.gz_|sc_IMGTrm.tsv.gz_|IMGTrm_filtered.tsv.gz_|nestor-rm_filtered.tsv.gz_|sc_nestor-rm.tsv.gz_|sc_|","",sequence_id),
         name = gsub("_H010","_H10",name),
         name = ifelse(duplicated(name) & grepl("E17_merged-B2-igg_consensus", name), paste0(name,"_2"), name)) %>%
  tidyr::drop_na(count) %>%
  dplyr::relocate(grp) %>%
  mutate(ID = substr(name, 1, 3),
         new_name = ifelse(nchar(name) > 0 & nchar(name) <= 10, paste0("sc_", name), name),
         timepoint = ifelse(grepl("-B1-",new_name), "B1",
                                 ifelse(grepl("-B2-", new_name), "B2",
                                         ifelse(grepl("igm", new_name), "PV", 
                                                ifelse(grepl("^sc", new_name), "Single-cell", "")))),
         ID_timepoint = paste(ID, timepoint, sep = "_")) %>%
  distinct(new_name, .keep_all = TRUE)

# remove large object that consumes memory
rm(clonotype_full)
gc()

# loop to save clonotype full  files and clonotype summary files
filtered_animal <- list()
clonotype_summary <- list()

for(animals in unique(clonotype_full_fixed$ID_timepoint)){
  ## save full clonotype files
  filtered_animal[[animals]] <- clonotype_full_fixed %>% filter(ID_timepoint == animals) %>% as.data.frame() 
  
#  write.csv(filtered_animal[[animals]], paste0("../", result.dir, animals,"_clonotype_full.csv"), row.names = FALSE)
  
  ## save summary files
  clonotype_summary[[animals]] <- filtered_animal[[animals]] %>%
  group_by(grp, timepoint, ID, ID_timepoint) %>%
  summarise(clonal_size = n(), first(v_call), first(j_call), first(cdr3_aa)) %>%
  arrange(desc(clonal_size)) %>%
  ungroup() 
  
#  write.csv(clonotype_summary[[animals]], paste0("../", result.dir, animals,"_clonotype_summary.csv"), row.names = FALSE)
  
}

to_recon <- data.table::rbindlist(clonotype_summary) %>%
  select(clonal_size, ID_timepoint) %>%
  group_by(clonal_size, ID_timepoint) %>%
  summarise(size = n()) 


for(i in unique(to_recon$ID_timepoint)){
  to_recon_table <- to_recon %>%
    filter(ID_timepoint == i) %>%
    select(clonal_size, size) 
  
 fwrite(to_recon_table, file = paste0("../",result.dir,i,"_file_to_recon.txt"), append = FALSE,sep = "\t", row.names = FALSE, col.names = FALSE)
}

# remove large object that consumes memory
rm(filtered_animal)
gc()

```

```{r antigen-specific_clones}

clonotype_rsv <- clonotype_full_fixed %>%
 # add from which single-cell clonotype each clone from the rep-seq is coming from and removing empty rows
      group_by(grp) %>% 
      mutate(intermediate_name = ifelse(grepl("^sc_", new_name), new_name, ""),
             sc_clone_grp = ifelse(any(timepoint == "Single-cell"), paste0(intermediate_name, collapse = ", "), ""),
             sc_clone_grp = sub(", , .*",  "", sc_clone_grp)) %>%
      ungroup()  %>%
      select(-intermediate_name) %>%
      relocate(sc_clone_grp, grp, new_name, ID_timepoint, ID, timepoint) %>%
      filter(sc_clone_grp != "")


  
## Code for saving and adjusting sequences from the same clonotype but classified as different specificities. For example, clone group 1, has a both a DP sequence and a PreF/PostF sequence inside, the DP sequence will be the priority. 

clonotype_rsv <- left_join(clonotype_rsv, query_ref, by = "name") %>%
  group_by(grp) %>%
  mutate(specificity_group = case_when(any(grepl("DP",specificity)) ~ "DP",
                                       any(grepl("PreF",specificity)) ~ "PreF",
                                       any(grepl("PostF",specificity)) ~ "PostF")) %>%
  ungroup() %>%
  relocate(specificity_group) 


# saving clonal groups with distinct specificities
#different_specificities <- table(clonotype_rsv$grp, clonotype_rsv$specificity) %>%
#  as.data.frame() %>%
#  group_by(Var1) %>%
#  mutate(sum_difference = sum(Freq)-max(Freq)) %>%
#  ungroup() %>%
#  filter(sum_difference > 0) %>% 
#  pull(Var1) %>% as.character()

#clonotype_rsv[clonotype_rsv$grp %in% different_specificities,] %>%
 # filter(grepl("^sc*",new_name)) %>%
#  relocate(specificity) %>%
#  rename(clonal_group = grp) %>% View()
# write.csv(paste0("../", result.dir, "to_fix_double_specificity.csv"), row.names = FALSE)

```

## Save intermediate files with only antigen-specific clones and processed columns

```{r saving_data_rds}

saveRDS(clonotype_full_fixed, paste0("../data/clonotypes/processed_clonotypes.rds"))

saveRDS(clonotype_rsv, paste0("../data/clonotypes/rsv-specific_clonotypes.rds"))

#clonotype_full_fixed <- readRDS("../data/clonotypes/IMGTrm/processed_clonotypes.rds")

#clonotype_rsv <- readRDS("../data/clonotypes/IMGTrm/rsv-specific_clonotypes.rds")

```

## Generate processed files for diversity index estimation

```{r rsv_per_timepoint_specificity}
# adding column for loop of ID, timepoint and specificity
clonotype_rsv <- clonotype_rsv %>%
  mutate(ID_timepoint_spec = paste0(ID_timepoint, "_", specificity_group))

# create empty lists for loop
filtered_animal_rsv <- list()
clonotype_summary_rsv <- list()

# loop to create summary and full clonotype files for saving and/or following analysis
for(animals in unique(clonotype_rsv$ID_timepoint_spec)){
  ## save full clonotype files
  filtered_animal_rsv[[animals]] <- clonotype_rsv %>% filter(ID_timepoint_spec == animals) %>% as.data.frame() 
  write.csv(filtered_animal_rsv[[animals]], paste0("../", result.dir, animals,"_clonotype_full.csv"), row.names = FALSE)
  
  ## save summary files
  clonotype_summary_rsv[[animals]] <- filtered_animal_rsv[[animals]] %>%
    group_by(grp, timepoint, ID, specificity_group, ID_timepoint_spec) %>%
    summarise(clonal_size = n(), first(v_call), first(j_call), first(cdr3_aa)) %>%
    arrange(desc(clonal_size)) %>%
    ungroup() 
  write.csv(clonotype_summary_rsv[[animals]], paste0("../", result.dir, animals,"_rsv_clonotype_summary.csv"), row.names = FALSE)
  
}

# doing the same thing but for total, that means not account for specificities (PreF, DP,PostF)
for(animals in unique(clonotype_rsv$ID_timepoint)){
  ## save summary files
  clonotype_summary_rsv[[paste0(animals, "_total")]] <- clonotype_rsv %>% filter(ID_timepoint == animals) %>% 
    as.data.frame()  %>%
    mutate(specificity_group = "Total",
           ID_timepoint_spec = paste0(ID_timepoint, "_", specificity_group)) %>%
    group_by(grp, timepoint, ID, specificity_group, ID_timepoint_spec) %>%
    summarise(clonal_size = n(), first(v_call), first(j_call), first(cdr3_aa)) %>%
    arrange(desc(clonal_size)) %>%
    ungroup() 
  write.csv(clonotype_summary_rsv[[animals]], paste0("../", result.dir, animals,"_rsv_clonotype_summary.csv"), row.names = FALSE)
  
}


# Save clonotype summary per animal, taking into account ID, timepoint and clonal group
filtered_animal_rsv_summary <- list()

for(animals in unique(clonotype_rsv$ID)){
  ## save summary files
 clonotype_rsv %>% filter(ID == animals) %>% 
   as.data.frame() %>%
    group_by(grp, timepoint, ID) %>%
    summarise(clonal_size = n(), single_cells = first(sc_clone_grp), v_call =first(v_call), j_call = first(j_call), cdr3_aa = first(cdr3_aa)) %>%
    arrange(desc(clonal_size)) %>%
    ungroup() %>%
  write.csv(paste0("../", result.dir, animals,"_rsv_clonotype_summary.csv"), row.names = FALSE)
} 
 



to_recon_rsv <- data.table::rbindlist(clonotype_summary_rsv) %>%
  select(clonal_size, ID_timepoint_spec) %>%
  group_by(clonal_size, ID_timepoint_spec) %>%
  summarise(size = n()) %>%
  ungroup()


for(i in unique(to_recon_rsv$ID_timepoint_spec)){
  to_recon_table <- to_recon_rsv %>%
    filter(ID_timepoint_spec == i) %>%
    select(clonal_size, size) 
  
 fwrite(to_recon_table, file = paste0("../",result.dir,i,"_rsv_file_to_recon.txt"), append = FALSE,sep = "\t", row.names = FALSE, col.names = FALSE)
}

```

## Calculating Species richness 

### Full repertoire diversity analysis

#### Chao1 estimates for full repertoire

```{r generate_chao1_estimates}

chao_full <- lapply(clonotype_summary, function(x) select(x, "clonal_size"))


#function to subsample based on value to subsample, replicate the subsampling 100 times for higher accuracy

chaox100 <- function(x, value_to_subsample){
  replicate(100, {
  subsample <-  vegan::rrarefy(x, as.double(value_to_subsample))
  chao <- vegan::estimateR(subsample, parallel = 8)
  return(chao)
})}


timepoints <- c("B1", "B2", "PV", "Single-cell")

chao_list_res_full <- list()
for(timepoint in timepoints){
  print(timepoint)
  filtered_full <- chao_full[grepl(timepoint, names(chao_full))]
  min_to_subsample <- min(unlist(lapply(filtered_full,colSums)))
  chao_list_res_full[[timepoint]] <- lapply(filtered_full, chaox100, min_to_subsample)
}

change_names <- function(x) {
  names(x) <- gsub("_.*","",names(x))
  x
}

## adjusted dataset for plotting
{
  chao_res_df_full <- purrr::map(chao_list_res_full, ~change_names(.x))
  chao_res_df_full <- rbindlist(chao_res_df_full, use.names = TRUE, idcol = TRUE)
  chao_res_df_full$algorithm <- rep(c("Obs", "Chao1", "Chao1_se", "ACE", "ACE_se"),nrow(chao_res_df_full)/5)
  
  #save intermediate file
  #full repertoire diversity x100 replicates
  chao_res_df_full %>%
    filter(algorithm %in% c("Chao1", "ACE")) %>%
    write.csv(paste0("../",result.dir, "full_repertoire_diversity.csv"), row.names = FALSE)
  #full repertoire diversity mean of x100 replicates per animal
  chao_res_df_full %>%
    filter(algorithm %in% c("Chao1", "ACE")) %>%
    group_by(algorithm, .id) %>%
    summarise_all(.funs = mean) %>%
    write.csv(paste0("../",result.dir, "full_repertoire_diversity_mean.csv"), row.names = FALSE)
  
  chao_res_df_full <- tidyr::pivot_longer(chao_res_df_full, cols = 2:(length( chao_res_df_full)-1),names_to = c("ID")) %>% 
    tidyr::separate(.id, c("Timepoint"), sep = "_") %>%
    mutate(Group = plyr::mapvalues(ID,c("E11", "E16", "E17", "E23", "E24",
  "E12", "E14", "E18", "E21"), 
c("NP","NP","NP","NP","NP",
  "SOL", "SOL", "SOL", "SOL")))
}


```

#### Chao1 plotting between groups for full repertoire

```{r}
chao_res_df_full %>%
  filter(algorithm != "Chao1_se" & algorithm != "ACE_se") %>%
  #filter(algorithm == "Chao1") %>%
  group_by(ID, Group, Timepoint, algorithm) %>%
  summarise(value = mean(value)) %>%
  ggplot(aes(x = Group, y = value, color = ID)) +
  geom_boxplot(coef = 6, aes(group = Group, fill = Group)) +
  geom_point(position = position_jitter()) +
  scale_y_log10() +
  scale_colour_brewer(palette = "Set1") +
  cowplot::theme_cowplot() +
  ggpubr::stat_compare_means(method = "wilcox.test", comparisons = list(c("NP", "SOL"))) +
  facet_wrap(~Timepoint + algorithm, ncol =  3)


ggsave(paste0("../",result.dir, "full_repertoire_diversity.pdf"), width = 10, height = 15)

```

### RSV-specific diversity analysis
#### Chao1 estimates for RSV-specific diversity

```{r generate_chao1_estimates_rsv}

rsv_chao <- lapply(clonotype_summary_rsv, function(x) select(x, "clonal_size"))


#function to subsample based on value to subsample, replicate the subsampling 100 times for higher accuracy

chaox100 <- function(x, value_to_subsample){
  replicate(100, {
  subsample <-  vegan::rrarefy(x, value_to_subsample)
  chao <- vegan::estimateR(subsample)
  return(chao)
})}

diff_spec_timepoints <- unique(substring(names(clonotype_summary_rsv),5))

chao_list_results <- list()
for(spec_timepoint in diff_spec_timepoints){
  print(spec_timepoint)
  rsv_filtered <- rsv_chao[grepl(spec_timepoint, names(rsv_chao))]
  min_to_subsample <- min(unlist(lapply(rsv_filtered,colSums)))
  chao_list_results[[spec_timepoint]] <- lapply(rsv_filtered, chaox100, min_to_subsample)
}

change_names <- function(x) {
  names(x) <- gsub("_.*","",names(x))
  x
}

## adjusted dataset for plotting
{
  chao_results_df <- purrr::map(chao_list_results, ~change_names(.x))
  chao_results_df <- rbindlist(chao_results_df, use.names = TRUE, idcol = TRUE, fill = TRUE)
  chao_results_df$algorithm <- rep(c("Obs", "Chao1", "Chao1_se", "ACE", "ACE_se"),nrow(chao_results_df)/5)
  #save intermediate file
  chao_results_df %>%
    filter(algorithm %in% c("Chao1", "ACE")) %>%
    dplyr::rename(Timepoint_specificity = .id) %>%
    write.csv(paste0("../",result.dir, "rsv_repertoire_diversity.csv"), row.names = FALSE)
  # diversity mean of x100 replicates per animal
  chao_results_df %>%
    filter(algorithm %in% c("Chao1", "ACE")) %>%
    dplyr::rename(Timepoint_specificity = .id) %>%
    group_by(algorithm, Timepoint_specificity) %>%
    summarise_all(.funs = mean) %>%
    write.csv(paste0("../",result.dir, "rsv_repertoire_diversity_mean.csv"), row.names = FALSE)
  
  chao_results_df <- tidyr::pivot_longer(chao_results_df, cols = 2:(length(chao_results_df)-1),names_to = c("ID")) %>% 
    tidyr::separate(.id, c("Timepoint", "Specificity"), sep = "_") %>%
    mutate(Group = plyr::mapvalues(ID,c("E11", "E16", "E17", "E23", "E24",
  "E12", "E14", "E18", "E21"), 
c("NP","NP","NP","NP","NP",
  "SOL", "SOL", "SOL", "SOL")))
}


```

#### Chao1 plotting between groups for RSV-specific diversity

```{r}
chao_results_df %>%
  filter(algorithm != "Chao1_se" & algorithm != "ACE_se") %>%
  filter(algorithm == "Chao1") %>%
  group_by(ID, Group, Timepoint, Specificity, algorithm) %>%
  summarise(value = mean(value)) %>%
  ggplot(aes(x = Group, y = value, color = ID)) +
  geom_boxplot(coef = 6, aes(group = Group, fill = Group)) +
  geom_point(position = position_jitter()) +
  scale_y_log10() +
  scale_colour_brewer(palette = "Set1") +
  ggpubr::stat_compare_means(method = "wilcox.test", comparisons = list(c("NP", "SOL")),
                             p.adjust.methods = "none", paired = FALSE, hide.ns = TRUE) +
  cowplot::theme_cowplot()+
  facet_wrap(Timepoint + algorithm ~ Specificity, ncol = 4)

ggsave(paste0("../",result.dir, "summarised_timepoint_specificities.pdf"), width = 20, height = 30)

```
## Calculating average SHM per database

```{r shm_avg_dbs_processing}

ls <- list.files("../data/clonotypes", recursive = T, full.names = T)
ls <- ls[grepl("rsv", ls)]
names(ls) <- basename(dirname(ls))
rds_merge <- lapply(ls, readRDS)
rds_merge <- rbindlist(rds_merge, idcol = TRUE, fill = TRUE)
rds_merge <- rds_merge %>%
  select(.id, specificity_group, sc_clone_grp, grp, new_name, ID_timepoint, V_SHM, V_aa_mut) %>%
  mutate(Timepoint = factor(gsub(".*_", "",ID_timepoint), levels = c("PV","B1", "B2","Single-cell")), 
         ID = gsub("_.*", "",ID_timepoint)) %>%
  group_by(.id, ID_timepoint) %>%
  distinct(new_name,.keep_all = TRUE) %>%
  ungroup()

rds_merge_stat <- rds_merge %>%
  group_by(.id) %>%
  summarise(SHM_mean = mean(V_SHM), SHM_sd = sd(V_SHM), size = n())

rds_merge_stat

fwrite(rds_merge_stat,paste0("../",result.dir, "merged_databases_shm.csv"),row.names = FALSE,sep = ",")
  
```

### Plot avg SHM

```{r plot_and_saving}

rds_merge %>%
  ggplot(aes(x = .id, y = V_SHM, color = Timepoint)) +
  geom_violin(trim = TRUE, draw_quantiles = TRUE) +
  labs(x = "") +
  ggprism::theme_prism()

```
### Plot clone size per animal per database

```{r plot_and_saving}

rds_summary <- rds_merge %>%
  group_by(.id, ID_timepoint, grp) %>%
  summarise(ID = first(ID), Timepoint = first(Timepoint),
            clonal_size = n(),
            database = .id,
            sc_clone_grp = first(sc_clone_grp)) %>%
  ungroup() %>%
  distinct()

rds_summary_noPV <- rds_summary %>%
  filter(Timepoint != "PV") 

rds_summary_noPV %>%
  ggplot(aes(x = ID, y = clonal_size, fill = ID)) +
  geom_boxplot() +
 # ggridges::geom_density_ridges() +
  #ggridges::theme_ridges() +
  scale_fill_viridis_d() +
  scale_y_log10() +
  ggprism::theme_prism() +
  theme(legend.position = "none")+
  facet_wrap(~Timepoint + database)

```
## Correlation clone size per animal per database

```{r correlation_clone}
df_all <- data.frame()
for(timepoints in unique(rds_summary_noPV$Timepoint)){
  for(databases in unique(rds_summary_noPV$database)){
    
    
  rds_timepoint <- rds_summary_noPV %>% 
    filter(Timepoint == timepoints, database == databases) %>%
    arrange(desc(clonal_size)) %>%
    pull(clonal_size)
  
  rds_indiv <- rds_summary_noPV %>%
    filter(database == "individualized",
           Timepoint == timepoints) %>% 
  arrange(desc(clonal_size)) %>% 
    pull(clonal_size)
  
  length(rds_indiv) <- length(rds_timepoint)
  
  df <- data.frame(size_indiv = rds_indiv,
                   clonal_size = rds_timepoint,
                   Timepoint = timepoints,
                   database = databases)
  df[is.na(df)] <- 0
  df_all <- rbind(df,df_all)
}}

df_all %>%
  ggplot(aes(x = size_indiv, y = clonal_size)) +
  geom_point(size = 1) +
  geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +
  scale_x_continuous(trans=scales::pseudo_log_trans(base = 10),
                    breaks = c(0,1,10,100,1000,10000)) +
  scale_y_continuous(trans=scales::pseudo_log_trans(base = 10),
                     breaks = c(0,1,10,100,1000,10000)) +
  labs(y = "Clonal size", x = "Clonal size\n(Individualized database)") +
  ggprism::theme_prism() +
  facet_wrap(~Timepoint + database)
  
#ggExtra::ggMarginal(g1, type = "histogram") 
#  facet_wrap(~Timepoint + database)

```
## Plot selected LORs with individualized database

```{r indv_lors_plot}
lor_mabs <- read.csv("../data/specificity/LORs_single-cells.csv")

rds_indiv <- rds_summary %>%
  filter(database == "individualized", 
         Timepoint != "Single-cell") %>%
  mutate(LOR = ifelse(grepl(pattern = paste0(lor_mabs$well_ID, collapse = "|"), x = sc_clone_grp), "cloned", "not_cloned"),
         LOR = factor(LOR, levels = c("cloned","not_cloned"), ordered = TRUE))


rds_indiv %>%
  ggplot(aes(x = Timepoint, y = clonal_size, group = grp)) +
   geom_line(data = rds_indiv[rds_indiv$LOR == "not_cloned",], aes(color = "not_cloned")) +
  geom_line(data = rds_indiv[rds_indiv$LOR == "cloned",], aes(color = "cloned")) +
 scale_color_manual(values = c("navyblue","grey95")) +
  scale_y_log10() +
  ggprism::theme_prism()+
  facet_wrap(~ID)

rds_indiv %>%
  filter(Timepoint == "B2", LOR == "cloned") %>%
  janitor::get_dupes(sc_clone_grp,grp, Timepoint)

rds_indiv %>%
  filter(Timepoint == "B2", LOR == "cloned") %>%
  distinct(sc_clone_grp,grp,.keep_all = TRUE)

```

## Take environment snapshot 
```{r}
renv::snapshot()
```


## SessionInfo
```{r}
sessionInfo()
```


